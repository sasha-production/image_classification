{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем библиотеки, даем доступ к нашему Google Disk"
      ],
      "metadata": {
        "id": "ONBj6bOBIxoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfz1E72QLH6A",
        "outputId": "2b7148c9-2910-45bd-c07f-8954fb2b55a7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from imutils import paths\n",
        "from PIL import Image\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset,Dataset\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем предварительно обученную модель ResNet-34 из PyTorch Hub - централизованного хранилища предварительно обученных моделей, предоставляемого PyTorch.\n",
        "\n",
        "1. torch.hub.load(): Эта функция позволяет загружать предварительно обученные модели из PyTorch Hub. Она принимает на вход три аргумента:\n",
        "   - 'pytorch/vision': Это указывает на модуль, содержащий предварительно обученные модели, в данном случае - модели компьютерного зрения.\n",
        "   - 'resnet34': Это название модели, которую нужно загрузить, в данном случае - ResNet-34.\n",
        "   - pretrained=True: Этот аргумент указывает, что нужно загрузить предварительно обученную версию модели, а не инициализировать ее случайными весами."
      ],
      "metadata": {
        "id": "pnFow-0WI6ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn-Y_zHcLJQh",
        "outputId": "28ffe029-0a76-47a5-e4e1-87beba27a468",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Замораживаем (отключения обновления) все параметры, кроме параметров слоев BatchNorm, в предварительно обученной модели ResNet-34.\n",
        "\n",
        "1. for name, param in model_resnet34.named_parameters(): - Этот цикл проходит по всем параметрам (весам и смещениям) в модели model_resnet34 и получает для каждого параметра его имя (name) и само значение параметра (param).\n",
        "\n",
        "2. if(\"bn\" not in name): - Этот условный блок проверяет, содержится ли в имени параметра (name) подстрока \"bn\". Если нет, то это означает, что данный параметр не относится к слоям BatchNorm.\n",
        "\n",
        "3. param.requires_grad = False - Эта строка устанавливает флаг requires_grad для текущего параметра в False. Это означает, что данный параметр не будет обновляться во время обучения модели, так как его градиент не будет вычисляться.\n",
        "\n",
        "Это делается для того, чтобы использовать предварительно обученную модель в качестве \"базы\" и обучать только нерегуляризированные слои, такие как BatchNorm. Это может помочь улучшить производительность модели, особенно когда размер обучающей выборки относительно мал."
      ],
      "metadata": {
        "id": "EH8YO3rLJZGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_resnet34.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "LndQQr3gLMFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Устанавливаем количество классов. Тоесть модель будет использоваться для классификации на 6 классах.\n",
        "\n",
        "2. Модификация последнего полносвязного слоя (fully connected layer) модели ResNet-34:\n",
        "   - model_resnet34.fc = nn.Sequential(...) - заменяет последний полносвязный слой в оригинальной модели ResNet-34 на новую последовательность операций.\n",
        "   - nn.Linear(model_resnet34.fc.in_features, 512) - создает новый полносвязный слой, который принимает количество входных признаков, равное размеру выходного вектора предыдущего слоя в модели ResNet-34, и выдает 512 выходов.\n",
        "   - nn.ReLU() - добавляет слой активации ReLU. ReLU возвращает ноль, если входное значение x меньше или равно нулю, и возвращает само входное значение x, если оно больше нуля.\n",
        "   - nn.Dropout() - добавляет слой dropout для регуляризации.\n",
        "   - nn.Linear(512, num_classes) - создает последний полносвязный слой, который преобразует 512 входных признаков в num_classes выходов (в данном случае 6).\n",
        "\n",
        "Таким образом, этот код модифицирует последний слой предварительно обученной модели ResNet-34, чтобы она могла выполнять классификацию на 6 классов вместо оригинальных 1000 классов, на которых она была обучена."
      ],
      "metadata": {
        "id": "dlpKyrEgJ4Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 6\n",
        "\n",
        "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512, num_classes))"
      ],
      "metadata": {
        "id": "Hdjwa_klLNuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяем функцию train(), которая выполняет обучение модели.\n",
        "\n",
        "1. Инициализация переменных:\n",
        "   - training_loss и valid_loss - переменные для хранения суммарных значений потерь во время обучения и валидации соответственно.\n",
        "   - model.train() переводит модель в режим обучения, чтобы включить такие операции, как dropout, batch normalization и т.д.\n",
        "\n",
        "2. Обучение модели:\n",
        "   - Проходит по батчам данных из train_loader.\n",
        "   - Для каждого батча:\n",
        "     - Обнуляет градиенты в оптимизаторе с помощью optimizer.zero_grad().\n",
        "     - Получает входные данные inputs и целевые значения targets, перемещая их на выбранное устройство (device).\n",
        "     - Вычисляет выходы модели output = model(inputs).\n",
        "     - Вычисляет функцию потерь loss = loss_fn(output, targets).\n",
        "     - Вычисляет градиенты loss.backward().\n",
        "     - Обновляет параметры модели с помощью optimizer.step().\n",
        "     - Суммирует значение потерь training_loss += loss.data.item() * inputs.size(0).\n",
        "   - Вычисляет усредненное значение потерь за эпоху training_loss /= len(train_loader.dataset).\n",
        "\n",
        "3. Переключение модели в режим оценки: model.eval() переводит модель в режим оценки, отключая такие операции, как dropout и batch normalization, которые нужны только во время обучения.\n",
        "\n",
        "4. Инициализация счетчиков:\n",
        "   - num_correct - количество правильно предсказанных примеров.\n",
        "   - num_examples - общее количество примеров в валидационном наборе.\n",
        "\n",
        "5. Проход по батчам валидационного набора:\n",
        "   - Для каждого батча:\n",
        "     - Получает входные данные inputs и целевые значения targets, перемещая их на выбранное устройство (device).\n",
        "     - Вычисляет выходы модели output = model(inputs).\n",
        "     - Вычисляет значение функции потерь loss = loss_fn(output, targets).\n",
        "     - Суммирует значение потерь valid_loss += loss.data.item() * inputs.size(0).\n",
        "     - Вычисляет количество правильно предсказанных примеров в батче:\n",
        "       - Находит индексы максимальных значений в выходе модели torch.max(F.softmax(output, dim=1), dim=1)[1].\n",
        "       - Сравнивает эти индексы с целевыми значениями targets и считает количество совпадений torch.eq().\n",
        "       - Суммирует количество правильных предсказаний num_correct += torch.sum(correct).item().\n",
        "       - Увеличивает количество примеров num_examples += correct.shape[0].\n",
        "\n",
        "6. Вычисление усредненного значения потерь:\n",
        "   - Делит суммарное значение потерь на количество примеров в валидационном наборе valid_loss /= len(val_loader.dataset).\n",
        "\n",
        "В итоге, этот код вычисляет две важные метрики для оценки модели на валидационном наборе:\n",
        "1. Значение функции потерь valid_loss.\n",
        "2. Точность модели num_correct / num_examples."
      ],
      "metadata": {
        "id": "n-GWeAdxK80L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=15, device=\"cpu\"):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "        valid_loss /= len(val_loader.dataset)"
      ],
      "metadata": {
        "id": "2O_4iuujLPfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем преобразования данных.\n",
        "\n",
        "1. Преобразования для обучения ('train'):\n",
        "   - transforms.RandomResizedCrop(224): Случайно изменяет размер и обрезает изображение до размера 224x224 пикселей.\n",
        "   - transforms.RandomHorizontalFlip(): Случайно отражает изображение по горизонтали.\n",
        "   - transforms.RandomRotation(degrees=15): Случайно поворачивает изображение на угол до 15 градусов.\n",
        "   - transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2): Случайно изменяет яркость, контраст и насыщенность цвета изображения.\n",
        "   - transforms.ToTensor(): Преобразует изображение в тензор PyTorch.\n",
        "   - transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): Нормализует изображение с использованием средних и стандартных отклонений, характерных для набора данных ImageNet.\n",
        "\n",
        "2. Преобразования для тестирования ('test'):\n",
        "   - transforms.Resize(256): Изменяет размер изображения до 256x256 пикселей.\n",
        "   - transforms.CenterCrop(224): Вырезает центральный фрагмент 224x224 пикселей.\n",
        "   - transforms.ToTensor(): Преобразует изображение в тензор PyTorch.\n",
        "   - transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): Нормализует изображение с использованием тех же средних и стандартных отклонений, что и для обучения."
      ],
      "metadata": {
        "id": "rmjNnJP1S-v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "rG63UZWVS8kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Задание пути к данным:\n",
        "   - data_dir = '/content/drive/My Drive/contest/data_contest/train': Устанавливает путь к директории, содержащей тренировочные данные.\n",
        "\n",
        "2. Создание датасетов:\n",
        "   - image_datasets = {'train': datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])}: Создает датасет ImageFolder для тренировочных данных, применяя к ним преобразования из data_transforms['train'].\n",
        "\n",
        "3. Получение списка изображений и их меток:\n",
        "   - image_folder = image_datasets['train'].imgs: Получает список всех изображений в тренировочном наборе.\n",
        "   - labels = [x[1] for x in image_folder]: Получает список меток (классов) для всех изображений.\n",
        "\n",
        "4. Разделение данных на тренировочную и валидационную выборки:\n",
        "   - train_indices, val_indices = train_test_split(range(len(image_folder)), test_size=0.2, random_state=42): Разделяет индексы изображений на тренировочную (80%) и валидационную (20%) выборки.\n",
        "\n",
        "5. Создание выборок для тренировки и валидации:\n",
        "   - train_sampler = SubsetRandomSampler(train_indices): Создает выборку для тренировки, используя случайные индексы из train_indices.\n",
        "   - val_sampler = SubsetRandomSampler(val_indices): Создает выборку для валидации, используя случайные индексы из val_indices.\n",
        "\n",
        "6. Создание загрузчиков данных (dataloaders):\n",
        "   - train_loader = DataLoader(image_datasets['train'], batch_size=16, sampler=train_sampler, num_workers=6): Создает загрузчик для тренировочных данных, используя train_sampler для формирования батчей.\n",
        "   - val_loader = DataLoader(image_datasets['train'], batch_size=16, sampler=val_sampler, num_workers=6): Создает загрузчик для валидационных данных, используя val_sampler для формирования батчей.\n",
        "   - dataloaders = {'train': DataLoader(image_datasets['train'], batch_size=16, shuffle=True, num_workers=6)}: Создает загрузчик для тренировочных данных с перемешиванием.\n",
        "\n",
        "7. Сохранение информации о датасете:\n",
        "   - dataset_sizes = {'train': len(image_datasets['train'])}: Сохраняет размер тренировочного набора.\n",
        "   - class_names = image_datasets['train'].classes: Сохраняет названия классов.\n",
        "\n",
        "Этот код готовит данные для обучения и валидации модели глубокого обучения, используя PyTorch. Он разделяет исходный набор данных на тренировочную и валидационную выборки, создает загрузчики данных, которые будут использоваться в процессе обучения"
      ],
      "metadata": {
        "id": "cz5AIM-1TOvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/contest/data_contest/train'\n",
        "image_datasets = {'train': datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
        "                                          data_transforms['train'])}\n",
        "image_folder = image_datasets['train'].imgs\n",
        "labels = [x[1] for x in image_folder]\n",
        "train_indices, val_indices = train_test_split(range(len(image_folder)), test_size=0.2, random_state=42)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(image_datasets['train'], batch_size=16, sampler=train_sampler, num_workers=6)\n",
        "val_loader = DataLoader(image_datasets['train'], batch_size=16, sampler=val_sampler, num_workers=6)\n",
        "\n",
        "dataloaders = {'train': DataLoader(image_datasets['train'], batch_size=16,\n",
        "                             shuffle=True, num_workers=6)}\n",
        "dataset_sizes = {'train': len(image_datasets['train'])}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8KZEZmELRWq",
        "outputId": "a17fc791-5498-4ed5-add3-f65a2201f5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяем настраиваемый датасет для тестовых данных и создаем загрузчик данных (DataLoader) для него.\n",
        "\n",
        "1. Определение класса CustomTestDataset:\n",
        "   - def __init__(self, image_paths, transform=None):: Конструктор класса, который принимает список путей к изображениям и необязательное преобразование для применения к изображениям.\n",
        "   - def __len__(self):: Возвращает количество изображений в датасете.\n",
        "   - def __getitem__(self, idx):: Возвращает изображение по указанному индексу. Он открывает файл изображения, преобразует его в формат RGB и применяет к нему заданное преобразование (если оно указано).\n",
        "\n",
        "2. Получение путей к тестовым изображениям:\n",
        "   - image_paths = sorted(list(paths.list_images('/content/drive/My Drive/contest/data_contest/test/test'))): Получает отсортированный список полных путей ко всем изображениям в директории /content/drive/My Drive/contest/data_contest/test/test.\n",
        "\n",
        "3. Создание экземпляра CustomTestDataset:\n",
        "   - custom_test_dataset = CustomTestDataset(image_paths, transform=data_transforms['test']): Создает экземпляр CustomTestDataset, используя список путей к изображениям и преобразования из data_transforms['test'].\n",
        "\n",
        "4. Создание DataLoader для тестовых данных:\n",
        "   - test_loader = DataLoader(custom_test_dataset, batch_size=16, shuffle=False, num_workers=6): Создает загрузчик данных для тестового датасета, используя размер батча 16, без перемешивания и с 6 рабочими процессами.\n",
        "\n",
        "5. Обновление словаря dataloaders и dataset_sizes:\n",
        "   - dataloaders['test'] = test_loader: Добавляет созданный загрузчик тестовых данных в словарь dataloaders.\n",
        "   - dataset_sizes['test'] = len(image_paths): Добавляет размер тестового датасета в словарь dataset_sizes.\n",
        "\n",
        "Этот код позволяет загружать и обрабатывать тестовые данные с помощью пользовательского датасета CustomTestDataset, который применяет к изображениям такие же преобразования, как и для тренировочных данных. Созданный загрузчик данных test_loader может быть использован для оценки модели на тестовом наборе."
      ],
      "metadata": {
        "id": "aYbKnVP4y2xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path.strip())\n",
        "        image = image.convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "image_paths = sorted(list(paths.list_images('/content/drive/My Drive/contest/data_contest/test/test')))\n",
        "\n",
        "custom_test_dataset = CustomTestDataset(image_paths, transform=data_transforms['test'])\n",
        "\n",
        "test_loader = DataLoader(custom_test_dataset, batch_size=16, shuffle=False, num_workers=6)\n",
        "dataloaders['test'] = test_loader\n",
        "dataset_sizes['test'] = len(image_paths)"
      ],
      "metadata": {
        "id": "L4wKmdhgLXpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Проверка доступности CUDA:\n",
        "   - if torch.cuda.is_available():: Проверяет, доступен ли CUDA на текущем устройстве.\n",
        "\n",
        "2. Установка устройства:\n",
        "   - device = torch.device(\"cuda\"): Если CUDA доступен, устанавливает устройство в качестве CUDA.\n",
        "   - device = torch.device(\"cpu\"): Если CUDA не доступен, устанавливает устройство в качестве CPU.\n",
        "\n",
        "   GPU (графические процессоры) обычно намного производительнее CPU (центральных процессоров) при выполнении параллельных вычислений."
      ],
      "metadata": {
        "id": "0WMhh_xX01Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "snaIDgfxLY-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Информация о данных"
      ],
      "metadata": {
        "id": "Mc1wEDSo1LT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g20zvecLal7",
        "outputId": "9a09c6e6-3de5-47f4-accd-e4bf3d43c8ca",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 180\n",
              "    Root location: /content/drive/My Drive/contest/data_contest/train/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=None)\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка производительности обученной модели на тестовом наборе данных.\n",
        "\n",
        "1. Инициализация счетчиков:\n",
        "   - correct = 0: Инициализирует счетчик правильных предсказаний.\n",
        "   - total = 0: Инициализирует счетчик общего количества тестовых примеров.\n",
        "\n",
        "2. Оценка модели в режиме без градиента:\n",
        "   - with torch.no_grad():: Этот блок выполняется без вычисления градиентов, что повышает эффективность, поскольку градиенты не нужны во время тестирования.\n",
        "\n",
        "3. Итерация по тестовому загрузчику данных:\n",
        "   - for data in test_loader:: Итерируется по батчам тестовых данных, загруженных через test_loader.\n",
        "   - images, labels = data[0].to(device), data[1].to(device): Извлекает изображения и соответствующие им метки классов из текущего батча и переносит их на выбранное устройство (CPU или GPU).\n",
        "\n",
        "4. Оценка модели и подсчет правильных предсказаний:\n",
        "   - outputs = model(images): Получает выходы модели для текущего батча изображений.\n",
        "   - _, predicted = torch.max(outputs.data, 1): Получает индексы классов с максимальными выходными значениями, что соответствует предсказанным классам.\n",
        "   - total += labels.size(0): Увеличивает счетчик общего количества тестовых примеров на размер текущего батча.\n",
        "   - correct += (predicted == labels).sum().item(): Увеличивает счетчик правильных предсказаний на количество примеров в текущем батче, для которых предсказанный класс совпадает с истинным классом.\n",
        "\n",
        "5. Вывод результатов:\n",
        "   - print('correct: {:d}  total: {:d}'.format(correct, total)): Выводит количество правильных предсказаний и общее количество тестовых примеров.\n",
        "   - print('accuracy = {:f}'.format(correct / total)): Вычисляет и выводит точность модели на тестовом наборе данных.\n",
        "\n",
        "Функция test_model оценивает производительность обученной модели на тестовом наборе данных и выводит общее количество правильных предсказаний, а также точность модели.\n"
      ],
      "metadata": {
        "id": "qN31M5Fj130T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet34.eval()\n",
        "test_predictions = []\n",
        "def test_model(model):\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_predictions.extend(predicted.cpu().numpy())"
      ],
      "metadata": {
        "id": "N53znAssLcLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Переносит модель на устройство:\n",
        "   - model_resnet34.to(device): Переносит модель ResNet-34 на устройство, указанное в переменной device. Это может быть либо CPU, либо GPU (если доступен и выбран).\n",
        "   - Это необходимо, чтобы все вычисления, связанные с моделью, выполнялись на том же устройстве, что и тренировочные и валидационные данные.\n",
        "\n",
        "2. Создает оптимизатор:\n",
        "   - optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001): Создает оптимизатор Adam с начальной скоростью обучения 0.001. Оптимизатор будет обновлять параметры модели во время обучения.\n",
        "\n",
        "3. Вызывает функцию train:\n",
        "   - train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_loader, val_loader, epochs=15, device=device): Вызывает функцию train, которая, вероятно, определена в другом месте кода. Эта функция отвечает за обучение модели ResNet-34.\n",
        "   - Она принимает следующие аргументы:\n",
        "     - model_resnet34: Экземпляр модели ResNet-34.\n",
        "     - optimizer: Оптимизатор, который будет использоваться для обновления параметров модели.\n",
        "     - torch.nn.CrossEntropyLoss(): Функция потерь, которая будет использоваться для оценки производительности модели.\n",
        "     - train_loader: Загрузчик данных для обучающего набора данных.\n",
        "     - val_loader: Загрузчик данных для валидационного набора данных.\n",
        "     - epochs=15: Число эпох, на протяжении которых будет производиться обучение модели.\n",
        "     - device=device: Устройство, на котором будут выполняться вычисления (CPU или GPU).\n",
        "\n",
        "Таким образом, этот код готовит модель ResNet-34 к обучению, создает оптимизатор и вызывает функцию обучения, используя заданные параметры и загрузчики данных. Обучение будет выполняться на том же устройстве, что и тренировочные данные.\n"
      ],
      "metadata": {
        "id": "HN97dgkn-uUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet34.to(device)\n",
        "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
        "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_loader, val_loader, epochs=15, device=device)"
      ],
      "metadata": {
        "id": "UOGM2uzgXFxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Создает словарь heroes, который сопоставляет числовые идентификаторы с соответствующими именами героев.\n",
        "\n",
        "2. Создает pandas DataFrame res_df, используя результаты предсказаний test_predictions. Столбец my_class содержит числовые идентификаторы предсказанных классов.\n",
        "\n",
        "3. Применяет функцию lambda к столбцу my_class DataFrame res_df. Эта функция использует словарь heroes для замены числовых идентификаторов на соответствующие имена героев. Результат записывается в новый столбец my_class.\n",
        "\n",
        "4. Извлекает пути к изображениям из test_loader.dataset.image_paths и создает новый столбец path в DataFrame res_df, содержащий только имена файлов (без полного пути).\n",
        "\n",
        "5. Добавляет новый столбец id с последовательными числовыми идентификаторами от 0 до 599 (предполагается, что в тестовом наборе 600 изображений).\n",
        "\n",
        "6. Переименовывает столбец my_class в class.\n",
        "\n",
        "7. Сохраняет DataFrame res_df в файл pred2.csv в формате CSV без индексов.\n",
        "\n",
        "В целом, этот код создает табличное представление результатов предсказаний модели, связывая предсказанные классы с именами героев, добавляя пути к изображениям и последовательные идентификаторы, а затем сохраняет это представление в CSV-файл."
      ],
      "metadata": {
        "id": "9n4JM3mQKSuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heroes = {0: 'Гароу', 1: 'Генос', 2: 'Сайтама', 3: 'Соник', 4: 'Татсумаки', 5: 'Фубуки'}\n",
        "res_df = pd.DataFrame(test_predictions, columns=['my_class'])\n",
        "res_df['my_class'] = res_df.apply(lambda item: heroes[item.my_class], axis=1)\n",
        "image_path = [path.split(os.path.sep)[-1] for path in test_loader.dataset.image_paths]\n",
        "res_df.insert(0, \"path\", image_path, True)\n",
        "res_df.insert(0, 'id', range(600), True)\n",
        "res_df.rename(columns={'my_class': 'class'}, inplace=True)\n",
        "res_df.to_csv('pred2.csv', index=False)\n"
      ],
      "metadata": {
        "id": "5uXaCrPVZzsj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
